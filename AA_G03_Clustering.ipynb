{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Clustering - Grupo 03**"
      ],
      "metadata": {
        "id": "ei1HSRBoarSA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Authors**\n",
        "\n",
        "- César López Mantecón - 100472092\n",
        "- Manuel Gómez-Plana Rodríguez - 100472310\n",
        "\n"
      ],
      "metadata": {
        "id": "eDyKaRCpa782"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Repositorio**\n",
        "\n",
        "Esta práctica se ha llevado a cabo en este [repositorio de github](https://github.com/ManuGPR/AA_P2_G03.git)\n",
        "\n",
        "## **Introducción**\n",
        "\n",
        "En este cuaderno se resolverá un problema de clustering usando un dataset de estrellas."
      ],
      "metadata": {
        "id": "WECMpeGIbBbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Carga de dataset**"
      ],
      "metadata": {
        "id": "78wqY2vTbcor"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga del dataset por drive**"
      ],
      "metadata": {
        "id": "FhLAhHxdbjTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ejecutar el cuaderno en drive\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "stars = pd.read_csv(\"/content/drive/MyDrive/stars_data.csv\") # acceder al csv en drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy0JXp9ubfCa",
        "outputId": "e525fd7a-831a-448d-b569-35ad9c1dcd6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Carga del dataset en local**"
      ],
      "metadata": {
        "id": "waXa-jutboRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "stars = pd.read_csv(\"stars_data.csv\")"
      ],
      "metadata": {
        "id": "yD0-_fe9buvx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "a72616bd-6a78-40c6-fa3f-feabb3b6e35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'starts_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b3bf2be54ca2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starts_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'starts_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Dataset**\n",
        "Este apartado contiene tanto la descripción del dataset como las transformaciones que tendremos que ejecutar antes de trabajar con él.\n",
        "\n",
        "## **1.1. Descripción del dataset**\n",
        "Como podemos ver en la salida del código, contamos con un dataset de 240 instancias y 6 características. De estas 6 características, 4 son numéricas y 2 son categóricas."
      ],
      "metadata": {
        "id": "pKUgOG4TbR4K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "64U0HNROae_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0664e8-7fc2-476b-9ecc-b64cd8f4baf1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 240 entries, 0 to 239\n",
            "Data columns (total 6 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Temperature     240 non-null    int64  \n",
            " 1   L               240 non-null    float64\n",
            " 2   R               240 non-null    float64\n",
            " 3   A_M             240 non-null    float64\n",
            " 4   Color           240 non-null    object \n",
            " 5   Spectral_Class  240 non-null    object \n",
            "dtypes: float64(3), int64(1), object(2)\n",
            "memory usage: 11.4+ KB\n"
          ]
        }
      ],
      "source": [
        "stars.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.2. Transformación de las variables categóricas**\n",
        "Como se puede observar en la salida del siguiente código, existe un problema con los valores del atributo color. Para esta columna, existen valores que deberían ser iguales, como se puede ver en tipos como \"Blue white\", \"Blue-white\" y \"Blue-White\". Estos valores deberían ser iguales, pero difieren en una mayúscula o en un guión solamente."
      ],
      "metadata": {
        "id": "YPxAcnPj66qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stars.Color.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bKTD7Q270Zt",
        "outputId": "e85fec07-9373-43db-9f77-6794adc4770a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Red', 'Blue White', 'White', 'Yellowish White', 'Blue white',\n",
              "       'Pale yellow orange', 'Blue', 'Blue-white', 'Whitish',\n",
              "       'yellow-white', 'Orange', 'White-Yellow', 'white', 'yellowish',\n",
              "       'Yellowish', 'Orange-Red', 'Blue-White'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para arreglarlo, usaremos el siguiente fragmento de código. En él, hacemos un mapeado, donde agrupamos las distintas formas de escribir un valor en una única, para luego sustituir los valores por estas clases mapeadas."
      ],
      "metadata": {
        "id": "DldGGBrL8OZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeado de colores\n",
        "mapping = {\n",
        "  \"Red\": [\"Red\"],\n",
        "  \"Orange-Red\": [\"Orange-Red\"],\n",
        "  \"Orange\": [\"Orange\"],\n",
        "  \"Yellow-Orange\": [\"Pale yellow orange\"],\n",
        "  \"Yellow\": [\"yellowish\", \"Yellowish\"],\n",
        "  \"White-Yellow\": [\"Yellowish White\", \"yellow-white\", \"White-Yellow\"],\n",
        "  \"White\": [\"White\", \"Whitish\", \"white\"],\n",
        "  \"Blue-White\": [\"Blue White\", \"Blue white\", \"Blue-white\", \"Blue-White\"],\n",
        "  \"Blue\": [\"Blue\"],\n",
        "}\n",
        "\n",
        "# Cambiamos los colores\n",
        "for target, source in mapping.items():\n",
        "  stars.loc[stars.Color.isin(source), 'Color'] = target\n",
        "\n",
        "stars.Color.unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8IMwiGN8OQj",
        "outputId": "e0f90c23-503d-4399-8dc2-a71b04388d8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Red', 'Blue-White', 'White', 'White-Yellow', 'Yellow-Orange',\n",
              "       'Blue', 'Orange', 'Yellow', 'Orange-Red'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. K-Means**\n",
        "En este apartado, se cubre una implementación propia del algoritmo K-Means, el cuál compararemos luego con el algoritmo de `scikit-learn`.\n",
        "\n",
        "## **2.1. MyK_Means**\n",
        "Primero, debemos realizar una implementación propia del K-Means, la cual llamaremos MyK_Means."
      ],
      "metadata": {
        "id": "cYaKdr_cdANb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "\n",
        "class MyK_Means:\n",
        "  def __init__(self, k: int, data: pd.DataFrame):\n",
        "    # Número de clusters\n",
        "    self.k = k\n",
        "\n",
        "    # Datos sobre los que trabajar\n",
        "    self.data = data\n",
        "\n",
        "    # Lista con centroides, index del centroide = value del centroide\n",
        "    self.centroids = []\n",
        "\n",
        "    # Lista con los clusters, index del centroide = lista con instancias de esos clusters\n",
        "    self.past_clusters = []\n",
        "    self.clusters = []\n",
        "\n",
        "    self.init_cluster()\n",
        "    self.init_centroid()\n",
        "\n",
        "  def init_cluster(self):\n",
        "    for key in range(self.k):\n",
        "      self.clusters.append(pd.DataFrame(columns=self.data.columns))\n",
        "\n",
        "  def init_centroid(self):\n",
        "    list_min = self.data.min().to_list()\n",
        "    list_max = self.data.max().to_list()\n",
        "\n",
        "    for key in range(self.k):\n",
        "      centroid_list = []\n",
        "      for column in range(len(self.data.columns)):\n",
        "        centroid_list.append(random()*(list_max[column] - list_min[column]) + list_min[column])\n",
        "      self.centroids.append(tuple(centroid_list))\n",
        "\n",
        "  def calculate_closest_centroid(self, row):\n",
        "    distances_cluster = []\n",
        "    for key in range(len(self.centroids)):\n",
        "      distances_cluster.append((self.calc_distance(self.centroids[key], row)))\n",
        "    return distances_cluster.index(min(distances_cluster))\n",
        "\n",
        "  def fit(self):\n",
        "    it = 0\n",
        "    while (True):\n",
        "      it += 1\n",
        "      self.past_clusters = []\n",
        "      for n in range (self.k):\n",
        "        self.past_clusters.append(self.clusters[n].copy(deep=True))\n",
        "      self.clusters = []\n",
        "      self.init_cluster()\n",
        "      for row in range(len(self.data)):\n",
        "        closest_centroid = self.calculate_closest_centroid(self.data.iloc[row, :])\n",
        "        self.clusters[closest_centroid].loc[len(self.clusters[closest_centroid])] = self.data.iloc[row, :]\n",
        "      self.recalculate_centroids()\n",
        "\n",
        "      if (self.check_variation()):\n",
        "        return it\n",
        "\n",
        "  @staticmethod\n",
        "  def calc_distance(vec1, vec2):\n",
        "    return numpy.linalg.norm(vec1-vec2)\n",
        "\n",
        "  def recalculate_centroids(self):\n",
        "    self.centroids = []\n",
        "    for index in range(len(self.clusters)):\n",
        "      self.centroids.append(self.clusters[index].mean())\n",
        "\n",
        "  def check_variation(self):\n",
        "    for i in range(self.k):\n",
        "      if not self.clusters[i].equals(self.past_clusters[i]):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "a = MyK_Means(3, stars.iloc[0:, 0:2])\n",
        "print(\"iteraciones: \", a.fit())\n",
        "\n",
        "plt.scatter(a.clusters[0].iloc[0: , 0], a.clusters[0].iloc[0:, 1], color=\"yellow\", label=\"datos\")\n",
        "plt.scatter(a.clusters[1].iloc[0: , 0], a.clusters[1].iloc[0:, 1], color=\"blue\", label=\"datos\")\n",
        "plt.scatter(a.clusters[2].iloc[0: , 0], a.clusters[2].iloc[0:, 1], color=\"green\", label=\"datos\")\n",
        "\n",
        "plt.scatter(*zip(*a.centroids), color=\"red\", label=\"destacados\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Y-wrtUtdg0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.2. PCA**\n",
        "**PROBABLEMENTE HAYA QUE MOVERLO DEBAJO PARA PODER HACER EL PCA CON VARIABLES CATEGÓRICAS TRANsFORMADAS.**\n",
        "\n",
        "Para poder realizar correctamente la comparación entre nuestro K_Means y el K_means implementado de `scikit-learn`, primero deberemos aplicar una reducción de dimensionalidad sobre el data-set. Para ello, usaremos PCA."
      ],
      "metadata": {
        "id": "yTCCxau2EgeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "stars = pca.fit_transform(stars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "mzHk4tkdEgWx",
        "outputId": "f16733c5-4728-4948-ceee-7f7e4d00efb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'Red'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-f56eb2930417>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         if (\n\u001b[1;32m   2000\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Red'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.3. Comparación**\n",
        "**PROBABLEMENTE HAYA QUE MOVERLO DEBAJO PARA PODER HACER EL PCA CON VARIABLES CATEGÓRICAS TRANSFORMADAS Y LUEGO COMPARARLOS.**\n",
        "\n",
        "Tras aplicar la transformación de datos, compararemos las implementaciones. Para poder compararlos justamente, es necesario que cuenten ambos con el mismo número de clusters."
      ],
      "metadata": {
        "id": "FUd9NFArEgO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import MyK_Means\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "my_kmeans = MyK_Means(3)"
      ],
      "metadata": {
        "id": "8Sc3vpwjEgGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Conversión de variables categóricas**\n",
        "En este apartado se muestran dos maneras de transformar las variables categóricas a variables numéricas. Empezaremos por one-hot encoding, y luego seguiremos con una codificación ordinal."
      ],
      "metadata": {
        "id": "9zJOq5nKG0cV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.1. One-Hot Encoding**\n",
        "CAMBIAR LOS ATRIBUTOS COLOR EN EL DATASET ORIGINAL\n",
        "\n",
        "\n",
        "La primera manera es hacer un One-Hot Encoding, que es parecido a una transformación a un mapa de bits."
      ],
      "metadata": {
        "id": "7TWEP9MGG0U5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Crea el preprocesador\n",
        "cat_transformer = Pipeline(\n",
        "  steps= [\n",
        "    ('onehot', OneHotEncoder())\n",
        "  ])\n",
        "\n",
        "# Se crea el transformador\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers = [\n",
        "      ('cat', cat_transformer, [\"Color\",\"Spectral_Class\"]),\n",
        "    ],\n",
        "    remainder = 'passthrough')\n",
        "onehot_stars = preprocessor.fit_transform(stars)\n",
        "\n",
        "# Se consiguen los nombres de las columnas\n",
        "cat_columns_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(input_features=[\"Color\", \"Spectral_Class\"])\n",
        "all_columns_names = list(cat_columns_names) + [\"Temperature\", \"L\", \"R\", \"A_M\"]\n",
        "\n",
        "# Se consigue el dataframe transformado\n",
        "onehot_df = pd.DataFrame(onehot_stars.toarray(), columns=all_columns_names)\n",
        "onehot_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfY1VYEeG0Nm",
        "outputId": "2dbd572e-5c12-4c88-a5b2-f00390143907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 240 entries, 0 to 239\n",
            "Data columns (total 28 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   Color_Blue                240 non-null    float64\n",
            " 1   Color_Blue White          240 non-null    float64\n",
            " 2   Color_Blue white          240 non-null    float64\n",
            " 3   Color_Blue-White          240 non-null    float64\n",
            " 4   Color_Blue-white          240 non-null    float64\n",
            " 5   Color_Orange              240 non-null    float64\n",
            " 6   Color_Orange-Red          240 non-null    float64\n",
            " 7   Color_Pale yellow orange  240 non-null    float64\n",
            " 8   Color_Red                 240 non-null    float64\n",
            " 9   Color_White               240 non-null    float64\n",
            " 10  Color_White-Yellow        240 non-null    float64\n",
            " 11  Color_Whitish             240 non-null    float64\n",
            " 12  Color_Yellowish           240 non-null    float64\n",
            " 13  Color_Yellowish White     240 non-null    float64\n",
            " 14  Color_white               240 non-null    float64\n",
            " 15  Color_yellow-white        240 non-null    float64\n",
            " 16  Color_yellowish           240 non-null    float64\n",
            " 17  Spectral_Class_A          240 non-null    float64\n",
            " 18  Spectral_Class_B          240 non-null    float64\n",
            " 19  Spectral_Class_F          240 non-null    float64\n",
            " 20  Spectral_Class_G          240 non-null    float64\n",
            " 21  Spectral_Class_K          240 non-null    float64\n",
            " 22  Spectral_Class_M          240 non-null    float64\n",
            " 23  Spectral_Class_O          240 non-null    float64\n",
            " 24  Temperature               240 non-null    float64\n",
            " 25  L                         240 non-null    float64\n",
            " 26  R                         240 non-null    float64\n",
            " 27  A_M                       240 non-null    float64\n",
            "dtypes: float64(28)\n",
            "memory usage: 52.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.2. Codificación ordinal**"
      ],
      "metadata": {
        "id": "-T0_31DtG0Fr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fGmyf6TeGz9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Modelos de clustering**\n",
        "En este apartado, se cubren dos modelos de clustering, con su posterior análisis y comparación de resultados."
      ],
      "metadata": {
        "id": "srzMz0U_Ra2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.1. DBSCAN**"
      ],
      "metadata": {
        "id": "-b2n9xDSRat7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# La PipeLine\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components=2)),\n",
        "    ('dbscan', DBSCAN())\n",
        "])\n",
        "\n",
        "# Se crea el grid y y se entrena el modelo con el dataset con onehot-encoding\n",
        "pipeline.fit(onehot_df)\n",
        "\n",
        "# Se imprimen los resultados\n",
        "labels = pipeline.named_steps['dbscan'].labels_\n",
        "silhouette_avg = silhouette_score(onehot_df, labels)\n",
        "\n",
        "print(\"Mejor score para DBSCAN con onehot-encoding\")\n",
        "print(silhouette_avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmKNNjeMRuL1",
        "outputId": "19566abc-7a33-40d8-aa24-b426e7efaae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor score para DBSCAN con onehot-encoding\n",
            "0.22526832680193365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uPpdqobnRad3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XyliNlATRaTP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}